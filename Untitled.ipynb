{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ccd6cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile \n",
    "from hmmlearn import hmm\n",
    "from python_speech_features import mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9b10b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to handle all HMM related processing\n",
    "class HMMTrainer(object):\n",
    "    def _init_(self, model_name='GaussianHMM', n_components=4, cov_type='diag', n_iter=1000):\n",
    "        self.model_name = model_name\n",
    "        self.n_components = n_components\n",
    "        self.cov_type = cov_type\n",
    "        self.n_iter = n_iter\n",
    "        self.models = []\n",
    "\n",
    "        if self.model_name == 'GaussianHMM':\n",
    "            self.model = hmm.GaussianHMM(n_components=self.n_components, \n",
    "                    covariance_type=self.cov_type, n_iter=self.n_iter)\n",
    "        else:\n",
    "            raise TypeError('Invalid model type')\n",
    "\n",
    "    # X is a 2D numpy array where each row is 13D\n",
    "    def train(self, X):\n",
    "        np.seterr(all='ignore')\n",
    "        self.models.append(self.model.fit(X))\n",
    "\n",
    "    # Run the model on input data\n",
    "    def get_score(self, input_data):\n",
    "        return self.model.score(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c6497525",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='_main_':\n",
    "    \n",
    "    input_folder = \"audio/\"\n",
    "\n",
    "    hmm_models = []\n",
    "\n",
    "    # Parse the input directory\n",
    "    for dirname in os.listdir(input_folder):\n",
    "        # Get the name of the subfolder \n",
    "        subfolder = os.path.join(input_folder, dirname)\n",
    "\n",
    "        if not os.path.isdir(subfolder): \n",
    "            continue\n",
    "\n",
    "        # Extract the label\n",
    "        label = subfolder[subfolder.rfind('\\\\\\\\') + 1:]\n",
    "\n",
    "        # Initialize variables\n",
    "        X = np.array([])\n",
    "        y_words = []\n",
    "\n",
    "        # Iterate through the audio files (leaving 1 file for testing in each class)\n",
    "        for filename in [x for x in os.listdir(subfolder) if x.endswith('.wav')][:-1]:\n",
    "            # Read the input file\n",
    "            filepath = os.path.join(subfolder, filename)\n",
    "            sampling_freq, audio = wavfile.read(filepath)\n",
    "            \n",
    "            # Extract MFCC features\n",
    "            mfcc_features = mfcc(audio, sampling_freq)\n",
    "\n",
    "            # Append to the variable X\n",
    "            if len(X) == 0:\n",
    "                X = mfcc_features\n",
    "            else:\n",
    "                X = np.append(X, mfcc_features, axis=0)\n",
    "            \n",
    "            # Append the label\n",
    "            y_words.append(label)\n",
    "\n",
    "        # Train and save HMM model\n",
    "        hmm_trainer = HMMTrainer()\n",
    "        hmm_trainer.train(X)\n",
    "        hmm_models.append((hmm_trainer, label))\n",
    "        hmm_trainer = None\n",
    "    \n",
    "    input_files = [\n",
    "            'audio/pineapple/pineapple09.wav',\n",
    "            'audio/orange/orange09.wav',\n",
    "            'audio/banana/banana09.wav',\n",
    "            'audio/kiwi/kiwi09.wav'\n",
    "            ]\n",
    "\n",
    "    # Classify input data\n",
    "    for input_file in input_files:\n",
    "        # Read input file\n",
    "        sampling_freq, audio = wavfile.read(input_file)\n",
    "\n",
    "        # Extract MFCC features\n",
    "        mfcc_features = mfcc(audio, sampling_freq)\n",
    "\n",
    "        # Define variables\n",
    "        max_score = hmm_models[0][0].get_score(mfcc_features)\n",
    "        output_label = None\n",
    "\n",
    "        # Iterate through all HMM models and pick \n",
    "        # the one with the highest score\n",
    "        for item in hmm_models:\n",
    "            hmm_model, label = item\n",
    "            score = hmm_model.get_score(mfcc_features)\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                output_label = label\n",
    "\n",
    "        # Print the output\n",
    "        print(\"\\nTrue:\", input_file[input_file.find('/')+1:input_file.rfind('/')])\n",
    "        print(\"Predicted:\", output_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b6cfef3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True: banana\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-96ddf87e47ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nTrue:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'output_label' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrue:\", input_file[input_file.find('/')+1:input_file.rfind('/')])\n",
    "print(\"Predicted:\", output_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "806c8ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True: banana\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-20c37c554bfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;31m# Print the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nTrue:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'output_label' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile \n",
    "from hmmlearn import hmm\n",
    "from python_speech_features import mfcc\n",
    "\n",
    "\n",
    "# Class to handle all HMM related processing\n",
    "class HMMTrainer(object):\n",
    "    def _init_(self, model_name='GaussianHMM', n_components=4, cov_type='diag', n_iter=1000):\n",
    "        self.model_name = model_name\n",
    "        self.n_components = n_components\n",
    "        self.cov_type = cov_type\n",
    "        self.n_iter = n_iter\n",
    "        self.models = []\n",
    "\n",
    "        if self.model_name == 'GaussianHMM':\n",
    "            self.model = hmm.GaussianHMM(n_components=self.n_components, \n",
    "                    covariance_type=self.cov_type, n_iter=self.n_iter)\n",
    "        else:\n",
    "            raise TypeError('Invalid model type')\n",
    "\n",
    "    # X is a 2D numpy array where each row is 13D\n",
    "    def train(self, X):\n",
    "        np.seterr(all='ignore')\n",
    "        self.models.append(self.model.fit(X))\n",
    "\n",
    "    # Run the model on input data\n",
    "    def get_score(self, input_data):\n",
    "        return self.model.score(input_data)\n",
    "\n",
    "if __name__=='_main_':\n",
    "    \n",
    "    input_folder = \"audio/\"\n",
    "\n",
    "    hmm_models = []\n",
    "\n",
    "    # Parse the input directory\n",
    "    for dirname in os.listdir(input_folder):\n",
    "        # Get the name of the subfolder \n",
    "        subfolder = os.path.join(input_folder, dirname)\n",
    "\n",
    "        if not os.path.isdir(subfolder): \n",
    "            continue\n",
    "\n",
    "        # Extract the label\n",
    "        label = subfolder[subfolder.rfind('\\\\\\\\') + 1:]\n",
    "\n",
    "        # Initialize variables\n",
    "        X = np.array([])\n",
    "        y_words = []\n",
    "\n",
    "        # Iterate through the audio files (leaving 1 file for testing in each class)\n",
    "        for filename in [x for x in os.listdir(subfolder) if x.endswith('.wav')][:-1]:\n",
    "            # Read the input file\n",
    "            filepath = os.path.join(subfolder, filename)\n",
    "            sampling_freq, audio = wavfile.read(filepath)\n",
    "            \n",
    "            # Extract MFCC features\n",
    "            mfcc_features = mfcc(audio, sampling_freq)\n",
    "\n",
    "            # Append to the variable X\n",
    "            if len(X) == 0:\n",
    "                X = mfcc_features\n",
    "            else:\n",
    "                X = np.append(X, mfcc_features, axis=0)\n",
    "            \n",
    "            # Append the label\n",
    "            y_words.append(label)\n",
    "\n",
    "        # Train and save HMM model\n",
    "        hmm_trainer = HMMTrainer()\n",
    "        hmm_trainer.train(X)\n",
    "        hmm_models.append((hmm_trainer, label))\n",
    "        hmm_trainer = None\n",
    "\n",
    "    # Test files\n",
    "    input_files = [\n",
    "            'audio/banana/banana15.wav',\n",
    "            'audio/orange/orange15.wav',\n",
    "            'audio/lime/lime15.wav',\n",
    "            'audio/pineapple/pineapple15.wav'\n",
    "            ]\n",
    "\n",
    "    # Classify input data\n",
    "    for input_file in input_files:\n",
    "        # Read input file\n",
    "        sampling_freq, audio = wavfile.read(input_file)\n",
    "\n",
    "        # Extract MFCC features\n",
    "        mfcc_features = mfcc(audio, sampling_freq)\n",
    "\n",
    "        # Define variables\n",
    "        max_score = hmm_models[0][0].get_score(mfcc_features)\n",
    "        output_label = None\n",
    "\n",
    "        # Iterate through all HMM models and pick \n",
    "        # the one with the highest score\n",
    "        for item in hmm_models:\n",
    "            hmm_model, label = item\n",
    "            score = hmm_model.get_score(mfcc_features)\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                output_label = label\n",
    "\n",
    "        # Print the output\n",
    "print(\"\\nTrue:\", input_file[input_file.find('/')+1:input_file.rfind('/')])\n",
    "print(\"Predicted:\", output_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12177c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf5a00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of spoken words: ['apple', 'banana', 'kiwi', 'lime', 'orange', 'peach', 'pineapple']\n",
      "{'peach', 'orange', 'pineapple', 'banana', 'kiwi', 'apple', 'lime'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "file_paths = []\n",
    "labels = []\n",
    "spoken_word = []\n",
    "for f in os.listdir('audio'):\n",
    "    for w in os.listdir('audio/' + f):  \n",
    "        file_paths.append('audio/' + f + '/' + w)\n",
    "        labels.append(f)\n",
    "        if f not in spoken_word:\n",
    "            spoken_word.append(f)\n",
    "print('List of spoken words:', spoken_word)\n",
    "print(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec835f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total files: 105\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "\n",
    "data = np.zeros((len(file_paths), 75550))\n",
    "maxsize = -1\n",
    "for n,file in enumerate(file_paths):\n",
    "    _, d = wavfile.read(file)\n",
    "    data[n, :d.shape[0]] = d\n",
    "    if d.shape[0] > maxsize:\n",
    "        maxsize = d.shape[0]\n",
    "        #print maxsize\n",
    "data = data[:, :maxsize]\n",
    "#Each sample file is one row in data, and has one entry in labels\n",
    "print('Number of total files:', data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8039449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and label indices [5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 6. 6. 6.\n",
      " 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "(105, 6966)\n"
     ]
    }
   ],
   "source": [
    "all_labels = np.zeros(data.shape[0])\n",
    "for n, l in enumerate(set(labels)):\n",
    "    all_labels[np.array([i for i, _ in enumerate(labels) if _ == l])] = n\n",
    "    \n",
    "print('Labels and label indices', all_labels)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c6948c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def stft(x, fftsize=512, overlap_pct=.8): # stft stands for \"Short Time Fourier Transform\"\n",
    "    hop = int(fftsize * (1 - overlap_pct))\n",
    "    w = scipy.hanning(fftsize + 1)[:-1]    \n",
    "    raw = np.array([np.fft.rfft(w * x[i:i + fftsize]) for i in range(0, len(x) - fftsize, hop)])\n",
    "    return raw[:, :(fftsize // 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f7a9f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "# Peaks in Amplitude vs Frequency graph and it is used as features of speech data. A better option is to use\n",
    "# MFCC(Mel-Frequency Cepstral Coefficients) which has been used later in the notebook.\n",
    "def peakfind(stft_data, n_peaks, l_size=3, r_size=3, c_size=3, f=np.mean):\n",
    "    window_size = l_size + r_size + c_size\n",
    "    shape = stft_data.shape[:-1] + (stft_data.shape[-1] - window_size + 1, window_size)\n",
    "    strides = stft_data.strides + (stft_data.strides[-1],)\n",
    "    xs = as_strided(stft_data, shape=shape, strides=strides)\n",
    "    def is_peak(stft_data):\n",
    "        centered = (np.argmax(data) == l_size + int(c_size/2))\n",
    "        l = stft_data[:l_size]\n",
    "        c = stft_data[l_size:l_size + c_size]\n",
    "        r = stft_data[-r_size:]\n",
    "        passes = np.max(c) > np.max([f(l), f(r)])\n",
    "        if centered and passes:\n",
    "            return np.max(c)\n",
    "        else:\n",
    "            return -1\n",
    "    r = np.apply_along_axis(is_peak, 1, xs)\n",
    "    top = np.argsort(r, None)[::-1]\n",
    "    heights = r[top[:n_peaks]]\n",
    "    #Add l_size and half - 1 of center size to get to actual peak location\n",
    "    top[top > -1] = top[top > -1] + l_size + int(c_size / 2.)\n",
    "    return heights, top[:n_peaks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76c3b020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6e861b6373f1>:5: DeprecationWarning: scipy.hanning is deprecated and will be removed in SciPy 2.0.0, use numpy.hanning instead\n",
      "  w = scipy.hanning(fftsize + 1)[:-1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c5f8a6509b94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpeakfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_peaks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-c6207f420c5e>\u001b[0m in \u001b[0;36mpeakfind\u001b[1;34m(stft_data, n_peaks, l_size, r_size, c_size, f)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_peak\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mtop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mheights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_peaks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mapply_along_axis\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36mapply_along_axis\u001b[1;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[0mbuff\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m         \u001b[0mbuff\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minarr_view\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-c6207f420c5e>\u001b[0m in \u001b[0;36mis_peak\u001b[1;34m(stft_data)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_strided\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstft_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mis_peak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstft_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mcentered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0ml_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_size\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstft_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ml_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstft_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ml_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mc_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m     \"\"\"\n\u001b[1;32m-> 1188\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_obs = []\n",
    "for i in range(data.shape[0]):\n",
    "    d = np.abs(stft(data[i, :]))\n",
    "    n_dim = 7\n",
    "    obs = np.zeros((n_dim, d.shape[0]))\n",
    "    for r in range(d.shape[0]):\n",
    "        _, t = peakfind(d[r, :], n_peaks=n_dim)\n",
    "        obs[:, r] = t.copy()\n",
    "    if i % 10 == 0:\n",
    "        print(\"Processed observation %s\" % i)\n",
    "    all_obs.append(obs)\n",
    "    \n",
    "all_obs = np.atleast_3d(all_obs)\n",
    "print(all_obs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f28ed761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "\n",
    "class gmmhmm:\n",
    "    def __init__(self, n_states):\n",
    "        self.n_states = n_states\n",
    "        self.random_state = np.random.RandomState(0)\n",
    "        \n",
    "        #Normalize random initial state\n",
    "        self.prior = self._normalize(self.random_state.rand(self.n_states, 1))  # Initialize prior probability \"Pi\"\n",
    "        self.A = self._stochasticize(self.random_state.rand(self.n_states, self.n_states)) # Initialize \"A\" probability\n",
    "        \n",
    "# Initializing mu, covariance and dimension matrix to calcuate \"B\" matrix       \n",
    "        self.mu = None\n",
    "        self.covs = None\n",
    "        self.n_dims = None\n",
    "           \n",
    "    def _forward(self, B):# B is basically bj(o(t))\n",
    "        log_likelihood = 0.\n",
    "        T = B.shape[1]  # B.shape = (n_state x Total_time)\n",
    "        alpha = np.zeros(B.shape) # n_states x Total_Time\n",
    "        for t in range(T):\n",
    "            if t == 0:\n",
    "                alpha[:, t] = B[:, t] * self.prior.ravel()\n",
    "            else:\n",
    "                alpha[:, t] = B[:, t] * np.dot(self.A.T, alpha[:, t - 1])\n",
    "         \n",
    "            alpha_sum = np.sum(alpha[:, t])\n",
    "            alpha[:, t] /= alpha_sum\n",
    "            log_likelihood = log_likelihood + np.log(alpha_sum)\n",
    "        return log_likelihood, alpha\n",
    "    \n",
    "    def _backward(self, B):\n",
    "        T = B.shape[1]\n",
    "        beta = np.zeros(B.shape);\n",
    "           \n",
    "        beta[:, -1] = np.ones(B.shape[0])\n",
    "            \n",
    "        for t in range(T - 1)[::-1]:\n",
    "            beta[:, t] = np.dot(self.A, (B[:, t + 1] * beta[:, t + 1]))\n",
    "            beta[:, t] /= np.sum(beta[:, t])\n",
    "        return beta\n",
    "# The product alpha_t(i)*beta_t(i) gives the probability of whole observation with the condition that at time t it was\n",
    "# in ith state. Alone alpha upto time T can't give this probability.\n",
    "       \n",
    "    \n",
    "    def _state_likelihood(self, obs):\n",
    "        obs = np.atleast_2d(obs)\n",
    "        B = np.zeros((self.n_states, obs.shape[1]))\n",
    "        for s in range(self.n_states): # Probability of getting the observation (o1,o2,...oT) when it is in state \"s\"\n",
    "            #Needs scipy 0.14\n",
    "            np.random.seed(self.random_state.randint(1))\n",
    "            B[s, :] = st.multivariate_normal.pdf(\n",
    "                obs.T, mean=self.mu[:, s].T, cov=self.covs[:, :, s].T)\n",
    "        return B\n",
    "    \n",
    "    def _normalize(self, x):\n",
    "        return (x + (x == 0)) / np.sum(x)\n",
    "    \n",
    "    def _stochasticize(self, x):\n",
    "        return (x + (x == 0)) / np.sum(x, axis=1)\n",
    "    \n",
    "    def _em_init(self, obs):\n",
    "        #Using this _em_init function allows for less required constructor args\n",
    "        if self.n_dims is None:\n",
    "            self.n_dims = obs.shape[0]\n",
    "        if self.mu is None:\n",
    "            subset = self.random_state.choice(np.arange(self.n_dims), size=self.n_states, replace=False)\n",
    "            self.mu = obs[:, subset]\n",
    "        if self.covs is None:\n",
    "            self.covs = np.zeros((self.n_states, self.n_dims, self.n_dims))\n",
    "            self.covs += np.diag(np.diag(np.cov(obs)))[:, :, None]\n",
    "        return self\n",
    "    \n",
    "    def _em_step(self, obs): \n",
    "        obs = np.atleast_2d(obs)\n",
    "        B = self._state_likelihood(obs)\n",
    "        T = obs.shape[1]\n",
    "        \n",
    "        log_likelihood, alpha = self._forward(B)\n",
    "        beta = self._backward(B)\n",
    "        \n",
    "        xi_sum = np.zeros((self.n_states, self.n_states))\n",
    "        gamma = np.zeros((self.n_states, T)) # gamma is the probability that it is in ith state at time t, given the\n",
    "        # observations and the model. gamma.shape = (n_state, T) \n",
    "        \n",
    "        for t in range(T - 1):\n",
    "            partial_sum = self.A * np.dot(alpha[:, t], (beta[:, t] * B[:, t + 1]).T)\n",
    "            xi_sum += self._normalize(partial_sum)\n",
    "            partial_g = alpha[:, t] * beta[:, t]\n",
    "            gamma[:, t] = self._normalize(partial_g)\n",
    "              \n",
    "        partial_g = alpha[:, -1] * beta[:, -1]\n",
    "        gamma[:, -1] = self._normalize(partial_g)\n",
    "        \n",
    "        expected_prior = gamma[:, 0]\n",
    "        expected_A = self._stochasticize(xi_sum)\n",
    "        \n",
    "        expected_mu = np.zeros((self.n_dims, self.n_states))\n",
    "        expected_covs = np.zeros((self.n_dims, self.n_dims, self.n_states))\n",
    "        \n",
    "        gamma_state_sum = np.sum(gamma, axis=1)\n",
    "        #Set zeros to 1 before dividing\n",
    "        gamma_state_sum = gamma_state_sum + (gamma_state_sum == 0)\n",
    "        \n",
    "        for s in range(self.n_states):\n",
    "            gamma_obs = obs * gamma[s, :]\n",
    "            expected_mu[:, s] = np.sum(gamma_obs, axis=1) / gamma_state_sum[s]\n",
    "            partial_covs = np.dot(gamma_obs, obs.T) / gamma_state_sum[s] - np.dot(expected_mu[:, s], expected_mu[:, s].T)\n",
    "            #Symmetrize\n",
    "            partial_covs = np.triu(partial_covs) + np.triu(partial_covs).T - np.diag(partial_covs)\n",
    "        \n",
    "        #Ensure positive semidefinite by adding diagonal loading\n",
    "        expected_covs += .01 * np.eye(self.n_dims)[:, :, None]\n",
    "        \n",
    "        self.prior = expected_prior\n",
    "        self.mu = expected_mu\n",
    "        self.covs = expected_covs\n",
    "        self.A = expected_A\n",
    "        return log_likelihood\n",
    "    \n",
    "    def train(self, obs, n_iter=15):\n",
    "        if len(obs.shape) == 2:\n",
    "            for i in range(n_iter):\n",
    "                self._em_init(obs)\n",
    "                log_likelihood = self._em_step(obs)\n",
    "        elif len(obs.shape) == 3:\n",
    "            count = obs.shape[0]\n",
    "            for n in range(count):\n",
    "                for i in range(n_iter):\n",
    "                    self._em_init(obs[n, :, :])\n",
    "                    log_likelihood = self._em_step(obs[n, :, :])\n",
    "        return self\n",
    "    \n",
    "    def test(self, obs):\n",
    "        if len(obs.shape) == 2:\n",
    "            B = self._state_likelihood(obs)\n",
    "            log_likelihood, _ = self._forward(B)\n",
    "            return log_likelihood\n",
    "        elif len(obs.shape) == 3:\n",
    "            count = obs.shape[0]\n",
    "            out = np.zeros((count,))\n",
    "            for n in range(count):\n",
    "                B = self._state_likelihood(obs[n, :, :])\n",
    "                log_likelihood, _ = self._forward(B)\n",
    "                out[n] = log_likelihood\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4d31cee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [0, 105]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-af9e0cb78026>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Size of training matrix:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Size of testing matrix:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2170\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2172\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \"\"\"\n\u001b[0;32m    298\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [0, 105]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_obs, all_labels, test_size = 0.3, random_state = 0)\n",
    "\n",
    "print('Size of training matrix:', X_train.shape)\n",
    "print('Size of testing matrix:', X_test.shape)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e021ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "THRESHOLD = 100\n",
    "CHUNK_SIZE = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "RATE = 44100\n",
    "\n",
    "def is_silent(snd_data):\n",
    "    return max(snd_data) < THRESHOLD\n",
    "\n",
    "def normalize(snd_data):\n",
    "    MAXIMUM = 16384\n",
    "    times = float(MAXIMUM)/max(abs(i) for i in snd_data)\n",
    "\n",
    "    r = array('h')\n",
    "    for i in snd_data:\n",
    "        r.append(int(i*times))\n",
    "    return r\n",
    "\n",
    "def trim(snd_data):\n",
    "    def _trim(snd_data):\n",
    "        snd_started = False\n",
    "        r = array('h')\n",
    "\n",
    "        for i in snd_data:\n",
    "            if not snd_started and abs(i)>THRESHOLD:\n",
    "                snd_started = True\n",
    "                r.append(i)\n",
    "\n",
    "            elif snd_started:\n",
    "                r.append(i)\n",
    "        return r\n",
    "\n",
    "    snd_data = _trim(snd_data)\n",
    "\n",
    "    snd_data.reverse()\n",
    "    snd_data = _trim(snd_data)\n",
    "    snd_data.reverse()\n",
    "    return snd_data\n",
    "\n",
    "def add_silence(snd_data, seconds):\n",
    "    r = array('h', [0 for i in xrange(int(seconds*RATE))])\n",
    "    r.extend(snd_data)\n",
    "    r.extend([0 for i in xrange(int(seconds*RATE))])\n",
    "    return r\n",
    "\n",
    "def record():\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=1, rate=RATE,\n",
    "        input=True, output=True,\n",
    "        frames_per_buffer=CHUNK_SIZE)\n",
    "\n",
    "    num_silent = 0\n",
    "    snd_started = False\n",
    "\n",
    "    r = array('h')\n",
    "\n",
    "    while 1:\n",
    "        # little endian, signed short\n",
    "        snd_data = array('h', stream.read(CHUNK_SIZE))\n",
    "        if byteorder == 'big':\n",
    "            snd_data.byteswap()\n",
    "        r.extend(snd_data)\n",
    "\n",
    "        silent = is_silent(snd_data)\n",
    "\n",
    "        if silent and snd_started:\n",
    "            num_silent += 1\n",
    "        elif not silent and not snd_started:\n",
    "            snd_started = True\n",
    "\n",
    "        if snd_started and num_silent > 30:\n",
    "            break\n",
    "\n",
    "    sample_width = p.get_sample_size(FORMAT)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    r = normalize(r)\n",
    "    r = trim(r)\n",
    "    r = add_silence(r, 0.05)\n",
    "    return sample_width, r\n",
    "\n",
    "def record_to_file(path):\n",
    "    sample_width, data = record()\n",
    "    data = pack('<' + ('h'*len(data)), *data)\n",
    "\n",
    "    wf = wave.open(path, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(sample_width)\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(data)\n",
    "    wf.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"please speak a word into the microphone\")\n",
    "    record_to_file('/home/prakash/Desktop/hmm-speech-recognition-0.1/Speech_Testing.wav')\n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6592f548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cfbe3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35afcb6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
